# SQBCP â€“ Sequence & Structure Based Cofactor Binding Predictor

**Dual-branch** prediktor vazby kofaktorÅ¯, vyuÅ¾Ã­vajÃ­cÃ­ ESM-2 embeddingy, grafovou neuronovou sÃ­Å¥ (GAT/GCN) s **heterogennÃ­m protein-ligand grafem** pro strukturnÃ­ data a 1D-CNN+Attention vÄ›tev pro sekvence bez struktury.

> **KlÃ­ÄovÃ© vlastnosti:**
> - Model se uÄÃ­ jak z PDB struktur (stovky), tak z anotovanÃ½ch sekvencÃ­ bez struktury (tisÃ­ce z UniProt)
> - **HeterogennÃ­ graf** â€“ proteinovÃ© i ligandovÃ© uzly s protein-ligand interakÄnÃ­mi hranami
> - Podpora **15 typÅ¯ kofaktorÅ¯**: NAD, NADP, FAD, FMN, ATP, ADP, AMP, GTP, GDP, COA, SAM, THF, PLP, TPP, HEM

---

## Architektura & logika

### Dual-branch architektura

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚           VSTUPNÃ DATA                  â”‚
                â”‚                                         â”‚
                â”‚  PDB struktury        Sekvence (UniProt)â”‚
                â”‚  (~500 s kofaktorem)  (~10 000 s anotacÃ­)â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚                     â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  GNN Branch           â”‚  â”‚ Sequence Branch      â”‚
            â”‚  (heterogennÃ­ graf)   â”‚  â”‚ (sequence_dataset)   â”‚
            â”‚                       â”‚  â”‚                      â”‚
            â”‚  PDB â†’ Binding Site   â”‚  â”‚ Sekvence â†’ ESM-2     â”‚
            â”‚  â†’ protein + ligand   â”‚  â”‚ embeddingy           â”‚
            â”‚    uzly               â”‚  â”‚ â†’ 1D-CNN (local      â”‚
            â”‚  â†’ P-P, P-L, L-L     â”‚  â”‚   motifs)            â”‚
            â”‚    hrany              â”‚  â”‚ â†’ Self-Attention     â”‚
            â”‚  â†’ GAT/GCN vrstvy    â”‚  â”‚ â†’ Learned pooling    â”‚
            â”‚  â†’ Protein-only      â”‚  â”‚                      â”‚
            â”‚    Attn pooling       â”‚  â”‚                      â”‚
            â”‚  [B, hidden_dim]      â”‚  â”‚ [B, hidden_dim]      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚                     â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  Shared Classifier   â”‚
                         â”‚  (sdÃ­lenÃ½ MLP)       â”‚
                         â”‚  â†’ 2 tÅ™Ã­dy           â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                          P(binds cofactor)
```

### Detail GNN Branch (strukturnÃ­ data) â€“ HeterogennÃ­ graf

```
PDB soubor
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Binding Site Extractorâ”‚  (Binding_site_ex.py)
â”‚  - parsuje PDB strukturu â”‚
â”‚  - najde ligand (kofaktor)â”‚
â”‚  - identifikuje residues â”‚
â”‚    do 6 Ã… od ligandu     â”‚
â”‚  - extrahuje ligandovÃ©   â”‚
â”‚    atomy + funkÄnÃ­ skupinyâ”‚
â”‚  - vytvoÅ™Ã­ kontaktnÃ­ mapuâ”‚
â”‚    (CÎ±-CÎ± < 8 Ã…)        â”‚
â”‚  - spoÄÃ­tÃ¡ P-L kontakty  â”‚
â”‚    (< 4.5 Ã…) s typem     â”‚
â”‚    interakce              â”‚
â”‚  - odhadne L-L kovalentnÃ­ â”‚
â”‚    vazby                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Node Features                                â”‚
â”‚                                                  â”‚
â”‚  PROTEINOVÃ‰ UZLY (1310D):     LIGANDOVÃ‰ UZLY (36D):  â”‚
â”‚  ESM-2 [1280]                 Element one-hot [5]â”‚
â”‚  + BLOSUM62 [20]              Func. skupina [14] â”‚
â”‚  + Physicochemical [7]        Aromaticita [1]    â”‚
â”‚  + Position [3]               N. vazeb [1]       â”‚
â”‚  (esm2_feature_ex.py          Cofactor ID [15]   â”‚
â”‚   + additional_features.py)   (LigandFeatures)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. HeterogennÃ­ Graf  (binding_site_graph.py)    â”‚
â”‚                                                  â”‚
â”‚  [Protein]â”€â”€P-Pâ”€â”€[Protein]   kontaktnÃ­ mapa      â”‚
â”‚  [Protein]â”€â”€P-Lâ”€â”€[Ligand]    interakÄnÃ­ hrany    â”‚
â”‚  [Ligand] â”€â”€L-Lâ”€â”€[Ligand]    kovalentnÃ­ vazby    â”‚
â”‚                                                  â”‚
â”‚  P-L edge attrs: distance + typ interakce (5D)   â”‚
â”‚  (hbond_candidate, hydrophobic, ionic, other)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. GNN (GAT/GCN)  (dual_predictor.py â†’ GNNBranch)â”‚
â”‚  - OddÄ›lenÃ© projekce:                            â”‚
â”‚    protein_projection (1310â†’256)                 â”‚
â”‚    ligand_projection (36â†’256)                    â”‚
â”‚  - Node type embedding (protein/ligand)          â”‚
â”‚  - 3Ã— GAT/GCN vrstvy (message passing)          â”‚
â”‚  - Protein-only Attention pooling                â”‚
â”‚    (ligand uzly vylouÄeny z poolingu)            â”‚
â”‚  â†’ graph embedding [256]                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detail Sequence Branch (sekvence bez struktury)

```
Sekvence (string)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. ESM-2 Embeddings     â”‚  (esm2_feature_ex.py)
â”‚  â†’ per-residue [L, 1280] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Sequence Branch      â”‚  (dual_predictor.py â†’ SequenceBranch)
â”‚  - Input projection      â”‚
â”‚  - 3Ã— 1D-CNN (lokÃ¡lnÃ­    â”‚
â”‚    motivy, kernel=5)     â”‚
â”‚  - Self-Attention        â”‚
â”‚  - Learned pooling       â”‚
â”‚  â†’ seq embedding [256]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### TrÃ©novacÃ­ reÅ¾imy

| ReÅ¾im | Vstup | VÄ›tev | Kdy pouÅ¾Ã­t |
|-------|-------|-------|------------|
| `sequence` | Sekvence (ESM emb.) | Seq branch + classifier | Sekvence bez struktury |
| `structure` | PyG graf (heterogennÃ­) | GNN branch + classifier | PDB data se strukturou |
| `both` | Oboje | ObÄ› + fusion + consistency | PDB data (obÄ› vÄ›tve) |

### Typy hran v heterogennÃ­m grafu

| Typ hrany | Zkratka | Zdroj | Edge atributy |
|-----------|---------|-------|---------------|
| Proteinâ€“Protein | P-P | KontaktnÃ­ mapa (CÎ±-CÎ± < 8Ã…) | vzdÃ¡lenost (1D) |
| Proteinâ€“Ligand | P-L | ProstorovÃ½ kontakt (< 4.5Ã…) | vzdÃ¡lenost + typ interakce (5D) |
| Ligandâ€“Ligand | L-L | KovalentnÃ­ vazby (0.5â€“1.9Ã…) | vzdÃ¡lenost (1D) |

**Typy interakcÃ­ P-L hran:** `hbond_candidate`, `hydrophobic`, `ionic`, `other`

### PodporovanÃ© kofaktory

| Kofaktor | FunkÄnÃ­ skupiny (mapovÃ¡nÃ­ atomÅ¯) |
|----------|----------------------------------|
| NAD/NADP | adenin, ribÃ³za, fosfÃ¡t, nikotinamid |
| FAD/FMN | isoalloxazin, ribitol, fosfÃ¡t, adenin |
| ATP/ADP/AMP | adenin, ribÃ³za, fosfÃ¡t |
| GTP/GDP | guanin, ribÃ³za, fosfÃ¡t |
| COA | adenin, ribÃ³za, fosfÃ¡t, pantothenÃ¡t, cysteamin |
| SAM, THF, PLP, TPP, HEM | (pÅ™eddefinovanÃ© v KNOWN_COFACTORS) |

### ProÄ tento pÅ™Ã­stup?

1. **ESM-2 embeddingy** â€“ protein language model trÃ©novanÃ½ na milionech sekvencÃ­ zachycuje evoluÄnÃ­ a strukturnÃ­ informaci bez potÅ™eby MSA
2. **HeterogennÃ­ graf** â€“ binding site jako graf s proteinovÃ½mi i ligandovÃ½mi uzly; GNN se uÄÃ­, jak protein interaguje s konkrÃ©tnÃ­m kofaktorem
3. **OddÄ›lenÃ© feature prostory** â€“ proteiny (1310D) a ligandy (36D) majÃ­ vlastnÃ­ projekce do sdÃ­lenÃ©ho prostoru, model se uÄÃ­ protein-ligand interakce skrze P-L hrany
4. **GAT (Graph Attention)** â€“ uÄÃ­ se, kterÃ© kontakty jsou dÅ¯leÅ¾itÄ›jÅ¡Ã­ pro predikci, vhodnÃ© pro malÃ© grafy (15â€“50 uzlÅ¯)
5. **Protein-only pooling** â€“ finÃ¡lnÃ­ graf embedding se poÄÃ­tÃ¡ pouze z proteinovÃ½ch uzlÅ¯; ligandovÃ© uzly slouÅ¾Ã­ k obohacenÃ­ proteinovÃ© reprezentace skrze message passing
6. **Dual-branch** â€“ vyuÅ¾Ã­vÃ¡ mnohem vÃ­ce sekvenÄnÃ­ch dat (tisÃ­ce z UniProt) vedle stovek PDB struktur
7. **Multi-cofactor ready** â€“ architektura nativnÄ› podporuje vÃ­ce typÅ¯ kofaktorÅ¯, rozÅ¡iÅ™itelnÃ¡ pÅ™idÃ¡nÃ­m novÃ½ch zÃ¡znamÅ¯ do `COFACTOR_FUNCTIONAL_GROUPS` a `KNOWN_COFACTORS`
8. **Consistency loss** â€“ na PDB datech penalizuje rozdÃ­l mezi GNN a Seq embeddingy â†’ Seq branch se uÄÃ­ aproximovat strukturnÃ­ informaci

---

## Instalace

```bash
# 1. VytvoÅ™it conda environment
conda env create -f environment.yml

# 2. Aktivovat
conda activate sqbcp
```

### GPU verze

V `environment.yml` zmÄ›nit:
```yaml
# smazat:
- cpuonly
# pÅ™idat:
- pytorch-cuda=12.1    # nebo vaÅ¡e verze CUDA
```

---

## PÅ™Ã­prava dat

### VstupnÃ­ data

- PDB soubory s navÃ¡zanÃ½m kofaktorem (NAD, ATP, FAD, COA, ...)
- UmÃ­stit do sloÅ¾ky, napÅ™. `./pdb_files/`

### Struktura PDB souboru

- MusÃ­ obsahovat protein chain s â‰¥10 residues
- MusÃ­ obsahovat kofaktor jako HETATM zÃ¡znam s danÃ½m jmÃ©nem (napÅ™. `NAD`)

### AutomatickÃ© staÅ¾enÃ­ dat

```bash
python download_data.py
# StÃ¡hne PDB soubory z RCSB + sekvence z UniProt
```

---

## PouÅ¾itÃ­ â€“ krok po kroku

### Krok 1: Extrakce binding sites z PDB

```python
from Binding_site_ex import BindingSiteExtractor
import glob

extractor = BindingSiteExtractor(distance_threshold=6.0)

pdb_files = glob.glob('./pdb_files/*.pdb')

binding_sites = []
for pdb_file in pdb_files:
    try:
        bs_info = extractor.extract_binding_site(pdb_file, ligand_name='NAD')
        binding_sites.append(bs_info)
        print(f"{pdb_file}: {bs_info['n_binding_site']} residues, "
              f"{len(bs_info.get('ligand_atoms', []))} ligand atoms, "
              f"{len(bs_info.get('protein_ligand_contacts', []))} P-L contacts")
    except Exception as e:
        print(f"Error {pdb_file}: {e}")

print(f"Celkem: {len(binding_sites)} struktur")
```

**VÃ½stup `extract_binding_site()` nynÃ­ obsahuje:**

| KlÃ­Ä | Typ | Popis |
|------|-----|-------|
| `full_sequence` | str | CelÃ¡ sekvence proteinu |
| `binding_site_sequence` | str | Sekvence binding site residues |
| `binding_site_indices` | list[int] | Indexy residues v sekvenci |
| `contact_map` | np.ndarray | CÎ±-CÎ± kontaktnÃ­ mapa (P-P hrany) |
| `ligand_atoms` | list[dict] | LigandovÃ© atomy: `{atom_name, element, coord, functional_group}` |
| `ligand_bonds` | list[tuple] | L-L kovalentnÃ­ vazby: `(atom_i, atom_j, distance)` |
| `protein_ligand_contacts` | list[dict] | P-L kontakty: `{residue_idx, atom_idx, distance, interaction_type}` |

**Parametry:**
- `distance_threshold` â€“ maximÃ¡lnÃ­ vzdÃ¡lenost atomu residue od ligandu (v Ã…), default 6.0
- `ligand_name` â€“ tÅ™Ã­pÃ­smennÃ½ kÃ³d ligandu v PDB (NAD, ATP, FAD, COA, ...)

### Krok 2: Extrakce ESM-2 embeddingÅ¯

```python
from esm2_feature_ex import ESMFeatureExtractor

esm_extractor = ESMFeatureExtractor(
    model_name="facebook/esm2_t33_650M_UR50D"
)

for bs_info in binding_sites:
    bs_embeddings = esm_extractor.extract_binding_site_embeddings(
        bs_info['full_sequence'],
        bs_info['binding_site_indices']
    )
    bs_info['esm_embeddings'] = bs_embeddings
    print(f"Embeddings shape: {bs_embeddings.shape}")
```

**DostupnÃ© modely ESM-2:**

| Model | Parametry | Embedding dim | PamÄ›Å¥ |
|-------|-----------|---------------|-------|
| `esm2_t30_150M_UR50D` | 150M | 640 | ~1 GB |
| `esm2_t33_650M_UR50D` | 650M | 1280 | ~3 GB |
| `esm2_t36_3B_UR50D` | 3B | 2560 | ~12 GB |

> **Pozor:** PÅ™i zmÄ›nÄ› modelu se zmÄ›nÃ­ `node_dim` v prediktoru!  
> 640 + 30 = 670 (pro 150M), 1280 + 30 = 1310 (pro 650M), 2560 + 30 = 2590 (pro 3B)

### Krok 3: SestavenÃ­ grafovÃ©ho datasetu (heterogennÃ­)

```python
from binding_site_graph import BindingSiteGraphDataset

# HeterogennÃ­ graf s protein + ligand uzly
dataset = BindingSiteGraphDataset(
    binding_sites,
    include_ligand=True,  # Zapnout ligandovÃ© uzly a P-L hrany
    feature_config={
        'use_esm': True,       # ESM-2 embeddingy (1280D)
        'use_blosum': True,    # BLOSUM62 encoding (20D)
        'use_physchem': True,  # Physicochemical (7D)
        'use_position': True   # RelativnÃ­ pozice (3D)
    }
)

graph = dataset[0]
print(f"GrafÅ¯: {len(dataset)}")
print(f"Protein uzlÅ¯: {graph.n_protein_nodes}")
print(f"Ligand uzlÅ¯: {graph.n_ligand_nodes}")
print(f"Node types: {graph.node_type}")        # 0=protein, 1=ligand
print(f"Edge types: {graph.edge_type.unique()}") # 0=P-P, 1=P-L, 2=L-L
print(f"Cofactor: {graph.cofactor_id}")
```

### Krok 4a: TrÃ©nink (jen PDB struktury â€“ GNN-only)

```python
import torch
from binding_site_predictor import BindingSiteNADPredictor
from train import Trainer
from torch_geometric.loader import DataLoader
from sklearn.model_selection import train_test_split

model = BindingSiteNADPredictor(
    node_dim=1310, ligand_dim=36, use_gat=True
)
train_graphs, val_graphs = train_test_split(dataset.graphs, test_size=0.2)
train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)
val_loader = DataLoader(val_graphs, batch_size=32)

trainer = Trainer(model, train_loader, val_loader, device='cpu')
trainer.train(num_epochs=100)
```

### Krok 4b: Dual trÃ©nink (PDB + sekvence â€“ doporuÄeno) ğŸ†•

VyuÅ¾Ã­vÃ¡ mnohem vÃ­ce dat â€“ sekvence z UniProt bez nutnosti 3D struktury:

```python
import torch
from dual_predictor import DualBranchPredictor
from dual_train import DualTrainer
from sequence_dataset import SequenceDataset, collate_sequences, load_sequences_from_csv
from torch.utils.data import DataLoader
from torch_geometric.loader import DataLoader as PyGDataLoader
from sklearn.model_selection import train_test_split

# 1. StrukturnÃ­ data (PDB) â€“ stÃ¡vajÃ­cÃ­ pipeline
train_graphs, val_graphs = train_test_split(dataset.graphs, test_size=0.2)
graph_train_loader = PyGDataLoader(train_graphs, batch_size=32, shuffle=True)
graph_val_loader = PyGDataLoader(val_graphs, batch_size=32)

# 2. SekvenÄnÃ­ data (UniProt) â€“ NOVÃ zdroj dat
sequences, labels = load_sequences_from_csv('data/nad_sequences.csv')
seq_dataset = SequenceDataset(sequences, labels, esm_extractor=esm)
seq_train, seq_val = train_test_split(list(range(len(seq_dataset))), test_size=0.2)
seq_train_loader = DataLoader(
    torch.utils.data.Subset(seq_dataset, seq_train),
    batch_size=16, shuffle=True, collate_fn=collate_sequences
)
seq_val_loader = DataLoader(
    torch.utils.data.Subset(seq_dataset, seq_val),
    batch_size=16, collate_fn=collate_sequences
)

# 3. Dual-branch model (s heterogennÃ­m grafem)
model = DualBranchPredictor(
    esm_dim=1280, node_dim=1310, ligand_dim=36,
    hidden_dim=256, num_gnn_layers=3, use_gat=True
)

# 4. Dual trainer
trainer = DualTrainer(
    model=model,
    graph_train_loader=graph_train_loader,
    graph_val_loader=graph_val_loader,
    seq_train_loader=seq_train_loader,
    seq_val_loader=seq_val_loader,
    device='cuda' if torch.cuda.is_available() else 'cpu',
    consistency_weight=0.3,
)
trainer.train(num_epochs=100)
```

NejlepÅ¡Ã­ model se automaticky uloÅ¾Ã­ jako `best_dual_model.pth`.

**VÃ½stup trÃ©ninku:**
```
Epoch 1/100
  Train - Loss: 0.6932, Acc: 0.5200
  Val   - Loss: 0.6815, Acc: 0.5800, AUC: 0.6120
  â†’ New best AUC: 0.6120
...
```

---

## Predikce

### A) Ze znÃ¡mÃ© struktury (PDB soubor)

```python
from Binding_site_ex import BindingSiteExtractor
from esm2_feature_ex import ESMFeatureExtractor
from additional_features import create_node_features
from binding_site_predictor import BindingSiteNADPredictor
from binding_site_graph import BindingSiteGraphDataset
import torch
import torch.nn.functional as F

# 1. NaÄÃ­st model (s podporou ligandovÃ½ch uzlÅ¯)
model = BindingSiteNADPredictor(node_dim=1310, ligand_dim=36, use_gat=True)
model.load_state_dict(torch.load('best_model.pth'))
model.eval()

# 2. Extrahovat binding site (vÄetnÄ› ligandovÃ½ch atomÅ¯)
extractor = BindingSiteExtractor(distance_threshold=6.0)
bs_info = extractor.extract_binding_site('query.pdb', ligand_name='NAD')

# 3. ESM embeddingy
esm = ESMFeatureExtractor()
bs_info['esm_embeddings'] = esm.extract_binding_site_embeddings(
    bs_info['full_sequence'], bs_info['binding_site_indices']
)

# 4. Sestavit heterogennÃ­ graf
dataset = BindingSiteGraphDataset([bs_info], include_ligand=True)
graph = dataset[0]

# 5. Predikce
with torch.no_grad():
    logits = model(graph)
    prob = F.softmax(logits, dim=1)[0, 1].item()

print(f"P(binds cofactor) = {prob:.4f}")
```

### B) Jen ze sekvence â€“ Dual model (doporuÄeno) ğŸ†•

```python
from dual_predictor import DualBranchPredictor
from esm2_feature_ex import ESMFeatureExtractor
import torch
import torch.nn.functional as F

# NaÄÃ­st dual model
model = DualBranchPredictor(
    esm_dim=1280, node_dim=1310, ligand_dim=36, use_gat=True
)
model.load_state_dict(torch.load('best_dual_model.pth'))
model.eval()

# ESM embeddings
esm = ESMFeatureExtractor()
sequence = "MKVLITGAGSGIGKAIA..."
emb = esm.extract_embeddings(sequence)  # [L, 1280]

# Predikce (sequence-only mode)
with torch.no_grad():
    esm_tensor = torch.FloatTensor(emb).unsqueeze(0)  # [1, L, 1280]
    logits, _ = model(mode='sequence', esm_embeddings=esm_tensor)
    prob = F.softmax(logits, dim=1)[0, 1].item()

print(f"P(binds cofactor) = {prob:.4f}")
```

> **VÃ½hoda dual modelu:** NevyÅ¾aduje kontaktnÃ­ mapu ani 3D strukturu. Seq branch se uÄil na tisÃ­cÃ­ch sekvencÃ­ â†’ pÅ™esnÄ›jÅ¡Ã­ neÅ¾ starÃ½ `seq_only_predictor.py`.

### C) Jen ze sekvence â€“ starÃ½ pÅ™Ã­stup (vyÅ¾aduje contact predictor)

```python
from seq_only_predictor import SequenceOnlyPredictor

predictor = SequenceOnlyPredictor(model, esm_extractor, contact_predictor)

sequence = "MKVLITGAGSGIGKAIA..."
prob = predictor.predict(sequence)
print(f"P(binds cofactor) = {prob:.4f}")
```

> **PoznÃ¡mka:** StarÅ¡Ã­ pÅ™Ã­stup â€“ vyÅ¾aduje contact predictor pro odhad kontaktnÃ­ mapy.

---

## Struktura projektu

```
â”œâ”€â”€ environment.yml           # Conda environment
â”œâ”€â”€ README.md                 # Tento soubor
â”‚
â”‚â”€â”€ # Data pipeline
â”œâ”€â”€ Binding_site_ex.py        # Extrakce binding site + ligandovÃ½ch atomÅ¯ z PDB
â”œâ”€â”€ esm2_feature_ex.py        # ESM-2 protein embeddingy
â”œâ”€â”€ additional_features.py    # BLOSUM, physicochemical, pozice + ğŸ†• LigandFeatures
â”œâ”€â”€ binding_site_graph.py     # ğŸ†• HeterogennÃ­ PyG grafy (protein + ligand uzly)
â”œâ”€â”€ sequence_dataset.py       # Dataset pro sekvence bez struktury
â”œâ”€â”€ download_data.py          # StaÅ¾enÃ­ PDB + UniProt dat
â”‚
â”‚â”€â”€ # Modely
â”œâ”€â”€ binding_site_predictor.py # GNN-only model (GAT/GCN) â€“ ğŸ†• heterogennÃ­ graf
â”œâ”€â”€ dual_predictor.py         # Dual-branch model (GNN + Seq) â€“ ğŸ†• heterogennÃ­ graf
â”œâ”€â”€ seq_only_predictor.py     # StarÅ¡Ã­ seq-only inference wrapper
â”‚
â”‚â”€â”€ # TrÃ©nink
â”œâ”€â”€ train.py                  # TrÃ©ninkovÃ¡ smyÄka (GNN-only)
â”œâ”€â”€ dual_train.py             # Dual training (PDB + sekvence)
â”œâ”€â”€ run_pipeline.py           # ğŸ†• HlavnÃ­ orchestraÄnÃ­ skript
â”‚
â”œâ”€â”€ *.pdb                     # PDB vstupnÃ­ soubory
â”œâ”€â”€ best_model.pth            # UloÅ¾enÃ½ GNN-only model
â””â”€â”€ best_dual_model.pth       # UloÅ¾enÃ½ dual model
```

## DÅ¯leÅ¾itÃ© poznÃ¡mky

1. **NegativnÃ­ vzorky** â€“ v aktuÃ¡lnÃ­ verzi jsou vÅ¡echny PDB struktury pozitivnÃ­ (obsahujÃ­ kofaktor). Pro trÃ©nink je nutnÃ© pÅ™idat negativnÃ­ vzorky (proteiny, kterÃ© kofaktor nevÃ¡Å¾ou), jinak model nebude schopen rozliÅ¡ovat.

2. **HeterogennÃ­ graf** â€“ `include_ligand=True` (default) vytvÃ¡Å™Ã­ graf s proteinovÃ½mi i ligandovÃ½mi uzly. Pokud chcete jen proteinovÃ½ graf (zpÄ›tnÄ› kompatibilnÃ­ reÅ¾im), nastavte `include_ligand=False`.

3. **Multi-cofactor rozÅ¡Ã­Å™enÃ­** â€“ pro pÅ™idÃ¡nÃ­ novÃ©ho kofaktoru:
   - PÅ™idejte mapovÃ¡nÃ­ atomÅ¯ do `COFACTOR_FUNCTIONAL_GROUPS` v [Binding_site_ex.py](Binding_site_ex.py)
   - PÅ™idejte kofaktor do `KNOWN_COFACTORS` v [additional_features.py](additional_features.py)
   - FunkÄnÃ­ skupiny pÅ™idejte do `FUNCTIONAL_GROUPS` v [additional_features.py](additional_features.py)

4. **Protein-only pooling** â€“ ligandovÃ© uzly obohacujÃ­ proteinovou reprezentaci skrze GNN message passing, ale NEjsou zahrnuty do finÃ¡lnÃ­ho graf embeddingu. To zajiÅ¡Å¥uje, Å¾e predikce je zaloÅ¾ena na proteinovÃ© odpovÄ›di na ligand, nikoli na ligandu samotnÃ©m.

5. **Batch size** â€“ pro malÃ© datasety (<100 grafÅ¯) sniÅ¾te `batch_size` na 8â€“16.

6. **PÅ™etrÃ©novÃ¡nÃ­** â€“ model mÃ¡ ~500k parametrÅ¯. PÅ™i malÃ©m datasetu zvaÅ¾te:
   - ZvÃ½Å¡it `dropout` (0.5 â†’ 0.7)
   - SnÃ­Å¾it `hidden_dim` (256 â†’ 128)
   - PouÅ¾Ã­t mÃ©nÄ› GNN vrstev (3 â†’ 2)

---

## RychlÃ½ start

```bash
# 1. Instalace
conda env create -f environment.yml
conda activate sqbcp

# 2. Test pipeline na jednom PDB souboru
python run_pipeline.py --test

# 3. StaÅ¾enÃ­ dat
python download_data.py

# 4. PlnÃ½ trÃ©nink
python run_pipeline.py --epochs 100 --ligand NAD
```

---

## Citace & reference

- **ESM-2**: Lin et al. (2023) "Evolutionary-scale prediction of atomic-level protein structure with a language model." *Science*
- **Kyte-Doolittle**: Kyte & Doolittle (1982) "A simple method for displaying the hydropathic character of a protein." *J Mol Biol* 157:105-132
- **BLOSUM62**: Henikoff & Henikoff (1992) "Amino acid substitution matrices from protein blocks." *PNAS* 89:10915-10919
- **Chou-Fasman**: Chou & Fasman (1978) "Prediction of the secondary structure of proteins from their amino acid sequence." *Adv Enzymol* 47:45-148
- **PyTorch Geometric**: Fey & Lenssen (2019) "Fast Graph Representation Learning with PyTorch Geometric." *ICLR Workshop*
